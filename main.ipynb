{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtV8yNXgSCil",
        "outputId": "6770be22-ca9a-4a66-b447-9b6ba1331c76"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "L8meK5R-SAhX"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import sys\n",
        "import logging\n",
        "import argparse\n",
        "import time\n",
        "from time import strftime\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import yaml\n",
        "import copy\n",
        "\n",
        "\n",
        "# Change to a directory in your Google Drive\n",
        "# os.chdir('/content/drive/MyDrive/Colab Notebooks')\n",
        "\n",
        "from vgg_cifar import vgg13\n",
        "\n",
        "# Modify sys.argv to remove unwanted arguments\n",
        "sys.argv = sys.argv[:1]\n",
        "\n",
        "# settings\n",
        "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 admm training')\n",
        "parser.add_argument('--epochs', type=int, default=160, metavar='N',\n",
        "                    help='number of epochs to train (default: 160)')\n",
        "parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
        "                    help='training batch size (default: 64)')\n",
        "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
        "                    help='random seed (default: 1)')\n",
        "parser.add_argument('--load-model-path', type=str, default=\"./model/cifar10_vgg13_acc_94.730.pt\",\n",
        "                    help='Path to pretrained model')\n",
        "parser.add_argument('--sparsity-type', type=str, default='unstructured',\n",
        "                    help=\"define sparsity_type: [unstructured, filter, etc.]\")\n",
        "parser.add_argument('--sparsity-method', type=str, default='omp',\n",
        "                    help=\"define sparsity_method: [omp, imp, etc.]\")\n",
        "parser.add_argument('--yaml-path', type=str, default=\"./pruning_ratio_unstructured.yaml\",\n",
        "                    help='Path to yaml file')\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "# --- for dubeg use ---------\n",
        "# args_list = [\n",
        "#     \"--epochs\", \"160\",\n",
        "#     \"--seed\", \"123\",\n",
        "#     # ... add other arguments and their values ...\n",
        "# ]\n",
        "# args = parser.parse_args(args_list)\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * float(correct) / float(len(test_loader.dataset))\n",
        "    print(\"===========================PRUNED MODEL==============================================\")\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset), accuracy))\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "def get_dataloaders(args):\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10('./data.cifar10', train=True, download=True,\n",
        "                         transform=transforms.Compose([\n",
        "                             transforms.Pad(4),\n",
        "                             transforms.RandomCrop(32),\n",
        "                             transforms.RandomHorizontalFlip(),\n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "                         ])),\n",
        "        batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.CIFAR10('./data.cifar10', train=False, download=True,\n",
        "                         transform=transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "                        ])),\n",
        "        batch_size=256, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "1IagZAG0SAhZ"
      },
      "outputs": [],
      "source": [
        "def read_prune_ratios_from_yaml(file_name, model):\n",
        "    \"\"\"\n",
        "    Reads user-defined layer-wise target pruning ratios from a yaml file.\n",
        "    Ensures that layer names in the yaml file match the model's layers.\n",
        "    \"\"\"\n",
        "    if not isinstance(file_name, str):\n",
        "        raise Exception(\"filename must be a string\")\n",
        "\n",
        "    with open(file_name, \"r\") as stream:\n",
        "        try:\n",
        "            raw_dict = yaml.safe_load(stream)\n",
        "            prune_ratio_dict = raw_dict['prune_ratios']\n",
        "\n",
        "            # Check if layer names match model layers\n",
        "            for layer_name in prune_ratio_dict:\n",
        "                if layer_name not in dict(model.named_modules()):\n",
        "                    print(f\"Warning: {layer_name} not found in the model!\")\n",
        "\n",
        "            return prune_ratio_dict\n",
        "\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "Hd2jl0WaSAha"
      },
      "outputs": [],
      "source": [
        "def unstructured_prune(tensor: torch.Tensor, sparsity: float) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Implement magnitude-based unstructured pruning for weight tensor (of a layer)\n",
        "    :param tensor: torch.(cuda.)Tensor, weight of conv/fc layer\n",
        "    :param sparsity: float, pruning sparsity\n",
        "    \n",
        "    :return:\n",
        "        torch.(cuda.)Tensor, pruning mask (1 for nonzeros, 0 for zeros)\n",
        "    \"\"\"\n",
        "    ##################### YOUR CODE STARTS HERE #####################\n",
        "\n",
        "    # Step 1: Calculate the number of weights to prune\n",
        "    num_elements = tensor.numel()\n",
        "    num_prune = int(sparsity * num_elements)\n",
        "\n",
        "    # Step 2: Find the threshold magnitude using absolute values of weights\n",
        "    threshold = torch.topk(torch.abs(tensor).view(-1), num_prune, largest=False).values[-1]\n",
        "\n",
        "    # Step 3: Create the pruning mask based on the absolute values\n",
        "    mask = torch.abs(tensor) > threshold \n",
        "\n",
        "    # Step 4: Apply mask to the tensor\n",
        "    tensor_pruned = tensor * mask.float()\n",
        "    ##################### YOUR CODE ENDS HERE #######################\n",
        "\n",
        "    # return the mask to record the pruning location ()\n",
        "    return mask.float()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "G1NA7SW4kwWt"
      },
      "outputs": [],
      "source": [
        "def filter_prune(tensor: torch.Tensor, sparsity: float) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    implement L2-norm-based filter pruning for weight tensor (of a layer)\n",
        "    :param tensor: torch.(cuda.)Tensor, weight of conv/fc layer\n",
        "    :param sparsity: float, pruning sparsity\n",
        "    \n",
        "    :return:\n",
        "        torch.(cuda.)Tensor, pruning mask (1 for nonzeros, 0 for zeros)\n",
        "    \"\"\"\n",
        "    \n",
        "    ##################### YOUR CODE STARTS HERE #####################\n",
        "    num_filters = tensor.shape[0]\n",
        "    num_prune = int(sparsity * num_filters)\n",
        "\n",
        "    # Calculate the L2 norm for each filter\n",
        "    filter_norms = torch.norm(tensor.view(num_filters, -1), p=2, dim=1)  \n",
        "    # Find the threshold norm for pruning\n",
        "    threshold = torch.topk(filter_norms, num_prune, largest=False).values[-1]\n",
        "\n",
        "    # Step 3: Get the pruning mask tensor based on the threshold\n",
        "    #         ||filter||2 <= th -> mask=0,\n",
        "    #         ||filter||2 >  th -> mask=1\n",
        "    mask = (filter_norms > threshold).float().view(-1, *[1] * (tensor.dim() - 1))\n",
        "    mask = mask.expand_as(tensor)  \n",
        "    \n",
        "    # Step 4: Apply mask tensor to the weight tensor\n",
        "    tensor_pruned = tensor * mask\n",
        "\n",
        "    ##################### YOUR CODE ENDS HERE #######################\n",
        "\n",
        "    # Return the mask to record the pruning location\n",
        "    return mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "def masked_retrain(model, sparsity_type, prune_ratio_dict, device, dataloader, criterion, optimizer, save_path, num_epochs=5):\n",
        "\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs * len(dataloader), eta_min=4e-08)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            # Accuracy computation\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print Epoch Num and Accuracy\n",
        "        epoch_accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Accuracy: {epoch_accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "        # Apply the pruning mask again to all layers after training\n",
        "        for name, module in model.named_modules():\n",
        "            if isinstance(module, nn.Conv2d):  \n",
        "                if name in prune_ratio_dict:\n",
        "                    sparsity = prune_ratio_dict[name]\n",
        "                    if sparsity_type == 'unstructured':\n",
        "                        mask = unstructured_prune(module.weight.data, sparsity)\n",
        "                    elif sparsity_type == 'filter':\n",
        "                        mask = filter_prune(module.weight.data, sparsity)\n",
        "\n",
        "                    # Apply the mask to the layer's weights to keep pruned weights as zero\n",
        "                    with torch.no_grad():\n",
        "                        module.weight.data *= mask  # Reapply mask to keep pruned weights zero\n",
        "\n",
        "\n",
        "    # Save the model\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model retrained and saved to {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "cl8dbu6aSAha"
      },
      "outputs": [],
      "source": [
        "def apply_pruning(model, sparsity_type, prune_ratio_dict, device, dataloader, criterion, optimizer, save_path):\n",
        "    \n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):  # find only conv layers\n",
        "            if name in prune_ratio_dict:\n",
        "                sparsity = prune_ratio_dict[name]\n",
        "                if sparsity_type == 'unstructured':\n",
        "                    # unstructured pruning\n",
        "                    mask = unstructured_prune(module.weight.data, sparsity)\n",
        "                elif sparsity_type == 'filter':\n",
        "                    # filter pruning \n",
        "                    mask = filter_prune(module.weight.data, sparsity)\n",
        "\n",
        "                # Apply mask \n",
        "                module.weight.data *= mask\n",
        "    \n",
        "    masked_retrain(model, sparsity_type, prune_ratio_dict, device, dataloader, criterion, optimizer, save_path, num_epochs=5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "GFgJjrdHSAhb"
      },
      "outputs": [],
      "source": [
        "def oneshot_magnitude_prune(model, sparsity_type, prune_ratio_dict, device, train_loader, criterion, optimizer, save_path, num_epochs=5 ):\n",
        "    \n",
        "    # Apply pruning (unstructured or filter)\n",
        "    apply_pruning(model, sparsity_type, prune_ratio_dict, device, train_loader, criterion, optimizer, save_path)\n",
        "\n",
        "    # Retrain the pruned model (masked retraining)\n",
        "    masked_retrain(model, sparsity_type, prune_ratio_dict, device, train_loader, criterion, optimizer, save_path ,num_epochs)\n",
        "    \n",
        "    # complete\n",
        "    print(\"==== OneShot Magnitude Training Complete ====\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [],
      "source": [
        "def iterative_magnitude_prune(model, prune_ratio_dict, sparsity_type, device, dataloader, criterion, optimizer, save_path, iterations=3, num_epochs=5):\n",
        "    \n",
        "    for iteration in range(iterations):\n",
        "        print(f\"==== Iteration {iteration + 1} of {iterations} ====\")\n",
        "\n",
        "        # current pruning ratios\n",
        "        current_prune_ratios = {\n",
        "            layer: prune_ratio_dict[layer] * ((iteration + 1) / iterations)\n",
        "            for layer in prune_ratio_dict\n",
        "        }\n",
        "\n",
        "        # apply pruning\n",
        "        print(\"Applying pruning...\")\n",
        "        apply_pruning(model, sparsity_type, current_prune_ratios, device, dataloader, criterion, optimizer, save_path)\n",
        "\n",
        "        # retraining\n",
        "        print(\"Retraining pruned model...\")\n",
        "        masked_retrain(model, sparsity_type, current_prune_ratios, device, dataloader, criterion, optimizer, save_path, num_epochs)\n",
        "\n",
        "    print(\"=== Iterative Magnitude Pruning Complete ===\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "NcNGSDesSAhb"
      },
      "outputs": [],
      "source": [
        "def test_sparity(model, sparsity_type=\"unstructured\"):\n",
        "    \n",
        "    print(f\"Sparsity type is: {sparsity_type}\")\n",
        "    total_zeros = 0\n",
        "    total_params = 0\n",
        "\n",
        "    conv_layers = {}\n",
        "    for name, layer in model.named_modules():\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            conv_layers[name +\".weight\"] = layer\n",
        "                \n",
        "    if sparsity_type == 'unstructured':\n",
        "      for name, param in model.named_parameters():\n",
        "          if 'weight' in name:\n",
        "                  if name == \"classifier.weight\" or param.numel()<1000:\n",
        "                    continue\n",
        "                  else:\n",
        "                    zero_count = (param == 0).sum().item()\n",
        "                    total_zeros += zero_count\n",
        "                    total_params += param.numel()\n",
        "                    print(f\"(zero/total) weights of {name} is: ({zero_count}/{param.numel()}). Sparsity is: {zero_count / param.numel():.4f}\")\n",
        "    \n",
        "    elif sparsity_type == 'filter':\n",
        "      for name, param in model.named_parameters(): \n",
        "          if name in conv_layers.keys():        \n",
        "            filters_zero = (param.view(param.size(0), -1).norm(p=2, dim=1) == 0).sum().item()\n",
        "            total_zeros += filters_zero\n",
        "            total_params += param.size(0)\n",
        "            print(f\"(empty/total) filters of {name} is: ({filters_zero}/{param.size(0)}). Filter sparsity is: {filters_zero / param.size(0):.4f}\")\n",
        "\n",
        "    overall_sparsity = (total_zeros / total_params)*100\n",
        "    print(f\"Total sparsity is: {overall_sparsity:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_pruned_filters(pruned_model: nn.Module) -> dict:\n",
        "   \n",
        "    pruned_filters_dict = {}\n",
        "\n",
        "    for name, layer in pruned_model.named_modules():\n",
        "        # Check if convolutional layer\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            # Get weight \n",
        "            weights = layer.weight.data\n",
        "            num_filters = weights.shape[0]  # Number of filters (output channels)\n",
        "            \n",
        "            # find filters that are pruned \n",
        "            pruned_filters = []\n",
        "            for i in range(num_filters):\n",
        "                if torch.all(weights[i] == 0):\n",
        "                    pruned_filters.append(i)\n",
        "            \n",
        "            if pruned_filters:\n",
        "                pruned_filters_dict[name] = pruned_filters\n",
        "\n",
        "\n",
        "    return pruned_filters_dict\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prune_channels_after_filter_prune(model, pruned_filter_dict):\n",
        "\n",
        "    for i, (layer_name, filter_indices) in enumerate(pruned_filter_dict.items()):\n",
        "        \n",
        "        # Determine the next layer's name\n",
        "        next_layer = list(pruned_filter_dict.keys())[i + 1] if i + 1 < len(pruned_filter_dict) else None\n",
        "        \n",
        "        if next_layer not in pruned_filter_dict:\n",
        "            continue\n",
        "        if next_layer == None:\n",
        "            continue\n",
        "        \n",
        "        \n",
        "        # prune the channels from the next layer\n",
        "        for name, module in model.named_modules():\n",
        "            if name == next_layer: \n",
        "                # Get the current weights of next layer\n",
        "                weight = module.weight.data\n",
        "                \n",
        "                # prune channels\n",
        "                for i in filter_indices:\n",
        "                    weight[:, i, :, :] = 0  \n",
        "\n",
        "                module.weight.data = weight\n",
        "                break\n",
        "        \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4ZXAaAfSAhb",
        "outputId": "33214d4e-6c8b-4806-e4a2-089bee851d0e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sv20002\\AppData\\Local\\Temp\\ipykernel_53144\\1989139815.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(args.load_model_path, map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "============================UNPRUNED MODEL===========================================\n",
            "===========================PRUNED MODEL==============================================\n",
            "Reading pruning ratios from ./pruning_ratio_unstructured.yaml...\n",
            "Applying Iterative magnitude unstructured pruning...\n",
            "==== Iteration 1 of 3 ====\n",
            "Applying pruning...\n",
            "Epoch [1/5], Accuracy: 99.98%\n",
            "Epoch [2/5], Accuracy: 99.98%\n",
            "Epoch [3/5], Accuracy: 99.97%\n",
            "Epoch [4/5], Accuracy: 99.99%\n",
            "Epoch [5/5], Accuracy: 99.97%\n",
            "Model retrained and saved to ./model/IMP_unstructured_0.8.pt\n",
            "Retraining pruned model...\n",
            "Epoch [1/5], Accuracy: 99.99%\n",
            "Epoch [2/5], Accuracy: 99.97%\n",
            "Epoch [3/5], Accuracy: 99.98%\n",
            "Epoch [4/5], Accuracy: 99.97%\n",
            "Epoch [5/5], Accuracy: 99.97%\n",
            "Model retrained and saved to ./model/IMP_unstructured_0.8.pt\n",
            "==== Iteration 2 of 3 ====\n",
            "Applying pruning...\n",
            "Epoch [1/5], Accuracy: 99.96%\n",
            "Epoch [2/5], Accuracy: 99.97%\n",
            "Epoch [3/5], Accuracy: 99.95%\n",
            "Epoch [4/5], Accuracy: 99.97%\n",
            "Epoch [5/5], Accuracy: 99.95%\n",
            "Model retrained and saved to ./model/IMP_unstructured_0.8.pt\n",
            "Retraining pruned model...\n",
            "Epoch [1/5], Accuracy: 99.96%\n",
            "Epoch [2/5], Accuracy: 99.97%\n",
            "Epoch [3/5], Accuracy: 99.97%\n",
            "Epoch [4/5], Accuracy: 99.96%\n",
            "Epoch [5/5], Accuracy: 99.97%\n",
            "Model retrained and saved to ./model/IMP_unstructured_0.8.pt\n",
            "==== Iteration 3 of 3 ====\n",
            "Applying pruning...\n",
            "Epoch [1/5], Accuracy: 99.63%\n",
            "Epoch [2/5], Accuracy: 99.52%\n",
            "Epoch [3/5], Accuracy: 99.60%\n",
            "Epoch [4/5], Accuracy: 99.51%\n",
            "Epoch [5/5], Accuracy: 99.58%\n",
            "Model retrained and saved to ./model/IMP_unstructured_0.8.pt\n",
            "Retraining pruned model...\n",
            "Epoch [1/5], Accuracy: 99.57%\n",
            "Epoch [2/5], Accuracy: 99.59%\n",
            "Epoch [3/5], Accuracy: 99.60%\n",
            "Epoch [4/5], Accuracy: 99.54%\n",
            "Epoch [5/5], Accuracy: 99.56%\n",
            "Model retrained and saved to ./model/IMP_unstructured_0.8.pt\n",
            "=== Iterative Magnitude Pruning Complete ===\n",
            "Testing the pruned and fine-tuned model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sv20002\\AppData\\Local\\Temp\\ipykernel_53144\\1989139815.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  pruned_model.load_state_dict(torch.load(save_path, map_location=device))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===========================PRUNED MODEL==============================================\n",
            "\n",
            "Test set: Average loss: -2.9464, Accuracy: 9378/10000 (93.7800%)\n",
            "\n",
            "Testing sparsity after pruning...\n",
            "Sparsity type is: unstructured\n",
            "(zero/total) weights of features.0.weight is: (0/1728). Sparsity is: 0.0000\n",
            "(zero/total) weights of features.3.weight is: (3686/36864). Sparsity is: 0.1000\n",
            "(zero/total) weights of features.7.weight is: (11059/73728). Sparsity is: 0.1500\n",
            "(zero/total) weights of features.10.weight is: (29491/147456). Sparsity is: 0.2000\n",
            "(zero/total) weights of features.14.weight is: (103219/294912). Sparsity is: 0.3500\n",
            "(zero/total) weights of features.17.weight is: (412876/589824). Sparsity is: 0.7000\n",
            "(zero/total) weights of features.21.weight is: (943718/1179648). Sparsity is: 0.8000\n",
            "(zero/total) weights of features.24.weight is: (2123366/2359296). Sparsity is: 0.9000\n",
            "(zero/total) weights of features.28.weight is: (2123366/2359296). Sparsity is: 0.9000\n",
            "(zero/total) weights of features.31.weight is: (1887436/2359296). Sparsity is: 0.8000\n",
            "Total sparsity is: 81.2399\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    # Setup random seed\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "    if use_cuda:\n",
        "        torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    # Set up model architecture and load pretrained dense model\n",
        "    model = vgg13()\n",
        "    model.to(device)\n",
        "    # Load model state dict with device mapping\n",
        "    model.load_state_dict(torch.load(args.load_model_path, map_location=device))\n",
        "\n",
        "\n",
        "    # Get the training and testing data loaders\n",
        "    train_loader, test_loader = get_dataloaders(args)\n",
        "\n",
        "    # Select loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "\n",
        "\n",
        "    # You may use this lr scheduler to fine-tune your pruned model.\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.epochs * len(train_loader), eta_min=1e-5)\n",
        "\n",
        "\n",
        "    print(\"============================UNPRUNED MODEL===========================================\")\n",
        "\n",
        "    # # Test the model after pruning and fine-tuning\n",
        "    # print(\"Testing the UNPRUNED model...\")\n",
        "    # test(model, device, test_loader)\n",
        "\n",
        "    # print(\"Sparsity of UNPRUNED model:\")\n",
        "    # test_sparity(model, \"unstructured\")\n",
        "\n",
        "\n",
        "    print(\"===========================PRUNED MODEL==============================================\")\n",
        "\n",
        "    model_copy = copy.deepcopy(model)\n",
        "    model_copy.to(device)\n",
        "    \n",
        "    # Read pruning ratios from the YAML file\n",
        "    print(f\"Reading pruning ratios from {args.yaml_path}...\")\n",
        "    prune_ratio_dict = read_prune_ratios_from_yaml(args.yaml_path, model)\n",
        "    # print(prune_ratio_dict)\n",
        "\n",
        "    pruning_type = \"unstructured\"\n",
        "    # save_path = \"./model/OMP_filter_0.4.pt\"\n",
        "\n",
        "    # # Apply OMP\n",
        "    # save_path = \"./model/OMP_unstructured_0.8.pt\" if pruning_type == \"unstructured\" else \"./model/OMP_filter_0.4.pt\"\n",
        "    # print(f'Applying oneshot magnitude {pruning_type} pruning...')\n",
        "    # oneshot_magnitude_prune(model_copy, pruning_type, prune_ratio_dict, device, train_loader, criterion, optimizer, save_path, num_epochs=5)\n",
        "\n",
        "    # Apply IMP\n",
        "    save_path = \"./model/IMP_unstructured_0.8.pt\" if pruning_type == \"unstructured\" else \"./model/IMP_filter_0.4.pt\"\n",
        "    print(f'Applying Iterative magnitude {pruning_type} pruning...')\n",
        "    iterative_magnitude_prune(model_copy, prune_ratio_dict, pruning_type, device, train_loader, criterion, optimizer, save_path, 3, 5)\n",
        "\n",
        "    pruned_model = vgg13()\n",
        "    pruned_model.to(device)\n",
        "    pruned_model.load_state_dict(torch.load(save_path, map_location=device))\n",
        "    \n",
        "    # Test the model after pruning and fine-tuning\n",
        "    print(\"Testing the pruned and fine-tuned model...\")\n",
        "    test(pruned_model, device, test_loader)\n",
        "\n",
        "    # Check model sparsity after pruning\n",
        "    print(\"Testing sparsity after pruning...\")\n",
        "    test_sparity(pruned_model, sparsity_type=pruning_type)\n",
        "    \n",
        "    # print(\"===========================TESTING CHANNEL PRUNED MODEL==============================================\")\n",
        "    \n",
        "    \n",
        "    # pruned_filters_dict = get_pruned_filters(pruned_model)    \n",
        "    # new_model = prune_channels_after_filter_prune(pruned_model, pruned_filters_dict)\n",
        "    \n",
        "    # print(\"Testing the pruned and fine-tuned model...\")\n",
        "    # test(pruned_model, device, test_loader)\n",
        "    \n",
        "    # print(\"Testing the PRUNED CHANNELS MODEL...\")\n",
        "    # test(new_model, device, test_loader)\n",
        "    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
